
@inproceedings{liang_scut-fbp5500_2018,
	title = {{SCUT}-{FBP}5500: A Diverse Benchmark Dataset for Multi-Paradigm Facial Beauty Prediction},
	doi = {10.1109/ICPR.2018.8546038},
	shorttitle = {{SCUT}-{FBP}5500},
	abstract = {Facial beauty prediction ({FBP}) is a significant visual recognition problem to make assessment of facial attractiveness that is consistent to human perception. To tackle this problem, various data-driven models, especially state-of-the-art deep learning techniques, were introduced, and benchmark dataset become one of the essential elements to achieve {FBP}. Previous works have formulated the recognition of facial beauty as a specific supervised learning problem of classification, regression or ranking, which indicates that {FBP} is intrinsically a computation problem with multiple paradigms. However, most of {FBP} benchmark datasets were built under specific computation constrains, which limits the performance and flexibility of the computational model trained on the dataset. In this paper, we argue that {FBP} is a multi-paradigm computation problem, and propose a new diverse benchmark dataset, called {SCUT}-{FBP}5500, to achieve multi-paradigm facial beauty prediction. The {SCUT}-{FBP}5500 dataset has totally 5500 frontal faces with diverse properties (male/female, Asian/Caucasian, ages) and diverse labels (face landmarks, beauty scores within [1], [5], beauty score distribution), which allows different computational models with different {FBP} paradigms, such as appearance-based/shape-based facial beauty classification/regression model for male/female of Asian/Caucasian. We evaluated the {SCUT}-{FBP}5500 dataset for {FBP} using different combinations of feature and predictor, and various deep learning methods. The results indicates the improvement of {FBP} and the potential applications based on the {SCUT}-{FBP}5500.},
	eventtitle = {2018 24th International Conference on Pattern Recognition ({ICPR})},
	pages = {1598--1603},
	booktitle = {2018 24th International Conference on Pattern Recognition ({ICPR})},
	author = {Liang, Lingyu and Lin, Luojun and Jin, Lianwen and Xie, Duorui and Li, Mengru},
	date = {2018-08},
	note = {{ISSN}: 1051-4651},
	keywords = {Benchmark testing, Computational modeling, Correlation, Databases, Predictive models, Standards},
	file = {IEEE Xplore Abstract Record:/home/snooze/Zotero/storage/9R3MK5QD/stamp.html:text/html;IEEE Xplore Full Text PDF:/home/snooze/Zotero/storage/ZTBT2XR3/Liang et al. - 2018 - SCUT-FBP5500 A Diverse Benchmark Dataset for Mult.pdf:application/pdf},
}

@inproceedings{xu_hierarchical_2019,
	title = {Hierarchical Multi-Task Network For Race, Gender and Facial Attractiveness Recognition},
	doi = {10.1109/ICIP.2019.8803614},
	abstract = {Deep learning has powered many face related tasks and shown state-of-the-art performance. However, existing deep models are often trained separately for different problems, which results in heavy computational burden. To address this problem, we propose a novel multi-task network with fully convolutional architecture-Hierarchical Multi-task Network ({HMT}-Net), that simultaneously recognizes a person's gender, race and facial attractiveness from a given portrait image. Aiming to improve the robustness to outliers in facial beauty prediction task, a novel loss is introduced into {HMTNet}. Compared to existing deep approaches, the proposed {HMTNet} achieves state-of-the-art performance on several datasets, and it can learn more discriminative feature representation through joint training and feature aggregation. Extensive experiments evidence the effectiveness of {HMTNet}.},
	eventtitle = {2019 {IEEE} International Conference on Image Processing ({ICIP})},
	pages = {3861--3865},
	booktitle = {2019 {IEEE} International Conference on Image Processing ({ICIP})},
	author = {Xu, Lu and Fan, Heng and Xiang, Jinhai},
	date = {2019-09},
	note = {{ISSN}: 2381-8549},
	keywords = {Computational modeling, Deep learning, Face, Face recognition, facial beauty prediction, Feature extraction, gender recognition, hierarchical multi-task neural network ({HMTNet}), multi-task learning, race recognition, Task analysis, Training},
	file = {IEEE Xplore Abstract Record:/home/snooze/Zotero/storage/WF6QUTBR/stamp.html:text/html;IEEE Xplore Full Text PDF:/home/snooze/Zotero/storage/5PWYFLC9/Xu et al. - 2019 - Hierarchical Multi-Task Network For Race, Gender a.pdf:application/pdf},
}

@article{j_iyer_machine_2021,
	title = {Machine Learning-Based Facial Beauty Prediction and Analysis of Frontal Facial Images Using Facial Landmarks and Traditional Image Descriptors},
	volume = {2021},
	issn = {1687-5273, 1687-5265},
	url = {https://www.hindawi.com/journals/cin/2021/4423407/},
	doi = {10.1155/2021/4423407},
	abstract = {The beauty industry has seen rapid growth in multiple countries and due to its applications in entertainment, the analysis and assessment of facial attractiveness have received attention from scientists, physicians, and artists because of digital media, plastic surgery, and cosmetics. An analysis of techniques is used in the assessment of facial beauty that considers facial ratios and facial qualities as elements to predict facial beauty. Here, the facial landmarks are extracted to calculate facial ratios according to Golden Ratios and Symmetry Ratios, and an ablation study is performed to find the best performing feature set from extracted ratios. Subsequently, Gray Level Covariance Matrix ({GLCM}), Hu’s Moments, and Color Histograms in the {HSV} space are extracted as texture, shape, and color features, respectively. Another ablation study is performed to find out which feature performs the best when concatenated with the facial landmarks. Experimental results show that the concatenation of primary facial characteristics with facial landmarks improved the prediction score of facial beauty. Four models are trained, K-Nearest Neighbors ({KNN}), Linear Regression ({LR}), Random Forest ({RF}), and Artificial Neural Network ({ANN}) on a dataset of 5500 frontal facial images, and amongst them, {KNN} performs the best for the concatenated features achieving a Pearson’s Correlation Coefficient of 0.7836 and a Mean Squared Error of 0.0963. Our analysis also provides us with insights into how different machine learning models can understand the concept of facial beauty.},
	pages = {1--14},
	journaltitle = {Computational Intelligence and Neuroscience},
	shortjournal = {Computational Intelligence and Neuroscience},
	author = {J. Iyer, Tharun and K., Rahul and Nersisson, Ruban and Zhuang, Zhemin and Joseph Raj, Alex Noel and Refayee, Imthiaz},
	editor = {López Rubio, Ezequiel},
	urldate = {2023-06-12},
	date = {2021-08-25},
	langid = {english},
	file = {J. Iyer et al. - 2021 - Machine Learning-Based Facial Beauty Prediction an.pdf:/home/snooze/Zotero/storage/D7RSAX5R/J. Iyer et al. - 2021 - Machine Learning-Based Facial Beauty Prediction an.pdf:application/pdf},
    year = {2021},
    journal = {Computational Intelligence and Neuroscience}
}

@article{valentine_why_2004,
	title = {Why are average faces attractive? The effect of view and averageness on the attractiveness of female faces},
	volume = {11},
	issn = {1069-9384, 1531-5320},
	url = {http://link.springer.com/10.3758/BF03196599},
	doi = {10.3758/BF03196599},
	shorttitle = {Why are average faces attractive?},
	pages = {482--487},
	number = {3},
	journaltitle = {Psychonomic Bulletin \& Review},
	shortjournal = {Psychonomic Bulletin \& Review},
	author = {Valentine, Tim and Darling, Stephen and Donnelly, Mary},
	urldate = {2023-06-21},
	date = {2004-06},
	langid = {english},
	file = {Valentine et al. - 2004 - Why are average faces attractive The effect of vi.pdf:/home/snooze/Zotero/storage/QKZPIPTS/Valentine et al. - 2004 - Why are average faces attractive The effect of vi.pdf:application/pdf},
}
